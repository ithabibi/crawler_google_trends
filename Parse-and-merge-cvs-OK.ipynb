{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به عنوان کدینگ پیش فرض فعال شد utf-8\n",
      "relatedQueries - 2025-01-02T031610.701.csv to همراه اول2021-03-01.csv successfully saved \n",
      "relatedQueries - 2025-01-02T031642.202.csv to ایرانسل2021-03-01.csv successfully saved \n",
      "relatedQueries - 2025-01-02T031750.564.csv to همراه اول2021-04-01.csv successfully saved \n",
      "relatedQueries - 2025-01-02T031821.976.csv to ایرانسل2021-04-01.csv successfully saved \n"
     ]
    }
   ],
   "source": [
    "import sys  # for utf8\n",
    "import csv\n",
    "import locale\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "#sys.stdout.reconfigure(encoding='utf-8')\n",
    "print(\"به عنوان کدینگ پیش فرض فعال شد\", sys.getdefaultencoding())\n",
    "\n",
    "directory_path = r\"C:\\related-dir\"  # مسیر دایرکتوری که فایل‌ها در آن قرار دارند\n",
    "\n",
    "# لیست کردن فایل‌ها در دایرکتوری\n",
    "for filename in os.listdir(directory_path):\n",
    "    # بررسی اینکه آیا نام فایل با عبارت 'relatedQueries' شروع می‌شود\n",
    "    if filename.startswith('relatedQueries'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        # خواندن فایل\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "            if len(lines) < 5:\n",
    "                print(filename + \" is empty\")\n",
    "                continue\n",
    "        # elif  # len(lines) > 40:  # تشخیص پر بودن فایل\n",
    "        date_line = lines[1].strip()  # استخراج تاریخ از خط دوم\n",
    "        # استخراج قسمت تاریخ از داخل پرانتز و حذف بخش های اضافی\n",
    "        date_string = date_line.split('(')[1].split('-')[0].strip()\n",
    "        # تبدیل رشته تاریخ به شیء تاریخ با فرمت مشخص\n",
    "        date_obj = datetime.strptime(date_string, '%m/%d/%y')\n",
    "        # تبدیل شیء تاریخ به رشته با فرمت yyyy-mm-dd\n",
    "        scrape_date = date_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "        start = date_line.find('\"') + 1  # موقعیت شروع\n",
    "        end = date_line.find(':')  # موقعیت پایان\n",
    "        # استخراج و حذف فضاهای اضافی\n",
    "        extracted_keyword = date_line[start:end].strip()\n",
    "\n",
    "        results = []  # لیست برای ذخیره نتایج\n",
    "        # متغیر برای پیگیری اینکه در بخش TOP یا RISING هستیم\n",
    "        current_section = None\n",
    "        # پردازش هر خط\n",
    "        for line in lines:\n",
    "            line = line.strip()  # حذف فضاهای اضافی\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            # شناسایی بخش‌های TOP و RISING\n",
    "            if line == \"TOP\":\n",
    "                current_section = \"TOP\"\n",
    "                continue\n",
    "            elif line == \"RISING\":\n",
    "                current_section = \"RISING\"\n",
    "                continue\n",
    "            # ذخیره نتایج بر اساس بخش فعلی\n",
    "            if current_section == \"TOP\":\n",
    "                results.append(f\"{line},{scrape_date},{extracted_keyword}, TOP\")\n",
    "            elif current_section == \"RISING\":\n",
    "                results.append(f\"{line},{scrape_date},{extracted_keyword}, RISING\")\n",
    "\n",
    "            # نوشتن نتایج در یک فایل جدید یا چاپ آنها\n",
    "            output_filename = scrape_date + extracted_keyword + '.csv'\n",
    "            with open(output_filename, 'w', encoding='utf-8') as output_file:\n",
    "                for result in results:\n",
    "                    output_file.write(result + '\\n')\n",
    "        print(filename + \" to \" + extracted_keyword +\n",
    "              scrape_date + \".csv successfully saved \")\n",
    "# ##############################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "فایل‌ها با موفقیت ادغام شدند و در merged_file.csv ذخیره شدند.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# مسیر دایرکتوری که فایل‌های CSV در آن قرار دارند\n",
    "directory = r'C:\\related-dir\\merge'\n",
    "\n",
    "# لیستی برای نگهداری دیتافریم‌ها\n",
    "dataframes = []\n",
    "\n",
    "# خواندن تمام فایل‌های CSV در دایرکتوری\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(file_path, encoding='utf-8', header=None)  # بدون در نظر گرفتن header\n",
    "        \n",
    "        # بررسی تعداد ستون‌ها\n",
    "        if df.shape[1] != 5:\n",
    "            print(f'خطا: فایل {filename} دارای {df.shape[1]} ستون است. انتظار می‌رفت 5 ستون باشد.')\n",
    "            continue  # این فایل را نادیده بگیر\n",
    "        \n",
    "        dataframes.append(df)\n",
    "\n",
    "# ادغام تمام دیتافریم‌ها\n",
    "if dataframes:  # اگر حداقل یک فایل معتبر وجود داشته باشد\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    # اضافه کردن ردیف عنوان (header)\n",
    "    header = ['ستون1', 'ستون2', 'ستون3', 'ستون4', 'ستون5']\n",
    "    merged_df.columns = header\n",
    "    \n",
    "    # ذخیره فایل ادغام شده به صورت CSV\n",
    "    output_path = os.path.join('merged_file.csv')\n",
    "    merged_df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f'فایل‌ها با موفقیت ادغام شدند و در {output_path} ذخیره شدند.')\n",
    "else:\n",
    "    print('هیچ فایل معتبری برای ادغام وجود ندارد.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
